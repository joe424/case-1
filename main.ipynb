{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"test1.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"F4d3iBKUdFxe","executionInfo":{"status":"ok","timestamp":1602908179902,"user_tz":-480,"elapsed":1063,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["# ref: https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfHlurxpdixu","executionInfo":{"status":"ok","timestamp":1602908179905,"user_tz":-480,"elapsed":1057,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}},"outputId":"2ad82727-0dda-4582-a11b-1a3a0a2f0c74","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PFudKDotd6Ub","executionInfo":{"status":"ok","timestamp":1602908179908,"user_tz":-480,"elapsed":1051,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}},"outputId":"d107879b-9294-47ee-83b5-a86c1dda9cf2","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#%cd /content/drive/My Drive/Case Presentation 1\n","%cd /content/drive/Shared drives/數位醫學/Case Presentation 1"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1403v7Kv9G42MNoj5JOfYxijc9VTDmStt/Case Presentation 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QR3Da0fcdFxi","executionInfo":{"status":"ok","timestamp":1602908180555,"user_tz":-480,"elapsed":1690,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["import torch\n","#!pip install torchtext\n","from torchtext import data"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXgdOaRfdFxl","executionInfo":{"status":"ok","timestamp":1602908180560,"user_tz":-480,"elapsed":1689,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["torch.manual_seed(2020);\n","torch.backends.cudnn.deterministic = True"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"z89MAi50dFxp","executionInfo":{"status":"ok","timestamp":1602908181527,"user_tz":-480,"elapsed":2652,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["#!pip install spacy\n","# !python -m spacy download en\n","import spacy\n","TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n","LABEL = data.LabelField(dtype = torch.float,batch_first=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3Kma1zzdFxr","executionInfo":{"status":"ok","timestamp":1602908181530,"user_tz":-480,"elapsed":2650,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["fields = [(None, None), ('text',TEXT),('label', LABEL)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XfZT9oddFxu","executionInfo":{"status":"ok","timestamp":1602908181934,"user_tz":-480,"elapsed":3049,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}},"outputId":"82890235-be98-41c1-e161-795b88329b32","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["train_data=data.TabularDataset(path = 'train_form.csv',format = 'csv',fields = fields,skip_header = True)\n","valid_data=data.TabularDataset(path = 'test_form.csv',format = 'csv',fields = fields,skip_header = True)\n","print(vars(train_data.examples[17]))\n","print(vars(valid_data.examples[17]))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["{'text': ['The', 'patient', 'denies', 'tobacco', 'and', '/', 'or', 'alcohol', 'use', '.'], 'label': '1'}\n","{'text': ['She', 'does', 'not', 'smoke', ',', 'does', 'not', 'use', 'birth', 'control', 'pills', ',', 'does', 'not', 'use', 'drugs', '.'], 'label': '1'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9sS5zT3DdFxx","executionInfo":{"status":"ok","timestamp":1602908181936,"user_tz":-480,"elapsed":3044,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["#import random\n","#train_data, valid_data = training_data.split(split_ratio=0.7, random_state = random.seed(2023))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHs0lUxodFx0","executionInfo":{"status":"ok","timestamp":1602908182531,"user_tz":-480,"elapsed":3635,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}},"outputId":"639a0e08-dfff-495d-b545-ca82b67ab77f","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["#initialize glove embeddings\n","TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\")  \n","LABEL.build_vocab(train_data)\n","\n","#No. of unique tokens in text\n","print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n","\n","#No. of unique tokens in label\n","print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n","\n","#Commonly used words\n","print(TEXT.vocab.freqs.most_common(150))  \n","\n","#Word dictionary\n","print(TEXT.vocab.stoi) \n","#print(LABEL.vocab.stoi)\n","inv_label_map = {v: k for k, v in LABEL.vocab.stoi.items()}\n","#print(inv_label_map)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Size of TEXT vocabulary: 30\n","Size of LABEL vocabulary: 4\n","[(',', 26), ('.', 22), ('unknown', 13), ('use', 11), ('tobacco', 10), ('and', 9), ('alcohol', 8), ('of', 7), ('/', 7), ('The', 6), ('patient', 6), ('history', 6), ('smoking', 6), ('She', 5), ('a', 4), ('-', 4), ('or', 4), ('denies', 4), ('quit', 4), ('in', 4), ('yo', 3), ('smoker', 3), (';', 3), ('does', 3), ('not', 3), ('smoke', 3), ('no', 3), ('drug', 3), ('smokes', 2), ('two', 2), ('per', 2), ('day', 2), ('has', 2), ('an', 2), ('approximately', 2), ('year', 2), ('pack', 2), ('years', 2), ('Conditions', 2), ('Infections', 2), ('Complications', 2), ('affecting', 2), ('Treatment', 2), ('Stay', 2), ('o', 2), ('with', 2), ('HTN', 2), ('chest', 2), ('hx', 2), ('hyperlipidemia', 2), ('Patient', 2), ('any', 2), ('as', 2), ('the', 2), ('past', 2), ('former', 2), ('for', 2), ('packs', 1), ('75-pack', 1), ('one', 1), ('x45', 1), ('crack', 1), ('schizoaffective', 1), ('d', 1), ('53', 1), ('M', 1), ('h', 1), ('hyperchol', 1), ('FH', 1), ('heart', 1), ('disease', 1), ('p', 1), ('w', 1), ('3', 1), ('wks', 1), ('pressure', 1), ('Atypical', 1), ('CP', 1), ('54', 1), ('htn', 1), ('DM', 1), ('TAH', 1), ('BSO', 1), ('age', 1), ('48', 1), ('atypical', 1), ('cp', 1), ('Current', 1), ('Smoker', 1), ('Depression', 1), ('Isoimmunization', 1), ('Rh', 1), ('Undesired', 1), ('Fertility', 1), ('EtOh', 1), ('abuse', 1), ('sinus', 1), ('bradycardia', 1), ('He', 1), ('admits', 1), ('to', 1), ('25', 1), ('50', 1), ('social', 1), ('Positive', 1), ('No', 1), ('Occasional', 1), ('Denies', 1), ('cigarette', 1), ('ethanol', 1), ('well', 1), ('recreational', 1), ('1985', 1), ('30', 1), ('ago', 1), ('1977', 1), ('Smoked', 1), ('47', 1), ('male', 1), ('PmHx', 1), ('here', 1), ('evaluation', 1), ('exertional', 1), ('tightness', 1), ('dyspnea', 1), ('weeks', 1), ('was', 1), ('prior', 1), ('off', 1), ('on', 1), ('but', 1), ('01/19', 1), ('Tobacco', 1), (':', 1), ('is', 1), ('user', 1), ('takes', 1), ('illicit', 1), ('drugs', 1)]\n","defaultdict(<function _default_unk_index at 0x7fa245094730>, {'<unk>': 0, '<pad>': 1, ',': 2, '.': 3, 'unknown': 4, 'use': 5, 'tobacco': 6, 'and': 7, 'alcohol': 8, '/': 9, 'of': 10, 'The': 11, 'history': 12, 'patient': 13, 'smoking': 14, 'She': 15, '-': 16, 'a': 17, 'denies': 18, 'in': 19, 'or': 20, 'quit': 21, ';': 22, 'does': 23, 'drug': 24, 'no': 25, 'not': 26, 'smoke': 27, 'smoker': 28, 'yo': 29})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"muoIAazUdFx3","executionInfo":{"status":"ok","timestamp":1602908182533,"user_tz":-480,"elapsed":3632,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}},"outputId":"162a850e-61f8-46c3-837a-7bb9efe401c8","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#check whether cuda is available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n","\n","#set batch size\n","BATCH_SIZE = 8\n","\n","#Load an iterator\n","train_iterator, valid_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data), \n","    batch_size = BATCH_SIZE,\n","    sort_key = lambda x: len(x.text),\n","    sort_within_batch=True,\n","    device = device)\n","device"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"gQfuzOwHdFx5","executionInfo":{"status":"ok","timestamp":1602908182535,"user_tz":-480,"elapsed":3629,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["import torch.nn as nn\n","\n","class classifier(nn.Module):\n","    \n","    #define all the layers used in model\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n","                 bidirectional, dropout):\n","        \n","        #Constructor\n","        super().__init__()          \n","        \n","        #embedding layer\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        #lstm layer\n","        self.lstm = nn.LSTM(embedding_dim, \n","                           hidden_dim, \n","                           num_layers=n_layers, \n","                           bidirectional=bidirectional, \n","                           dropout=dropout,\n","                           batch_first=True)\n","        \n","        #dense layer\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","\n","        #activation function\n","        self.act = nn.Sigmoid()\n","        \n","    def forward(self, text, text_lengths):\n","        \n","        #text = [batch size,sent_length]\n","        self.embedding = self.embedding\n","        embedded = self.embedding(text)\n","        #embedded = [batch size, sent_len, emb dim]\n","      \n","        #packed sequence\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n","        \n","        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n","        #hidden = [batch size, num layers * num directions,hid dim]\n","        #cell = [batch size, num layers * num directions,hid dim]\n","        \n","        #concat the final forward and backward hidden state\n","        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n","                \n","        #hidden = [batch size, hid dim * num directions]\n","        dense_outputs=self.fc(hidden)\n","\n","        #Final activation function\n","        outputs=self.act(dense_outputs)\n","        \n","        return outputs"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"DviyJg6AdFx7","executionInfo":{"status":"ok","timestamp":1602908182536,"user_tz":-480,"elapsed":3625,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["#define hyperparameters\n","size_of_vocab = len(TEXT.vocab)\n","embedding_dim = 100\n","num_hidden_nodes = 32\n","num_output_nodes = 4\n","num_layers = 2\n","bidirection = True\n","dropout = 0.2\n","\n","#instantiate the model\n","model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n","                   bidirectional = True, dropout = dropout)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"9PsZhnfydFx9","executionInfo":{"status":"ok","timestamp":1602908182537,"user_tz":-480,"elapsed":3619,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}},"outputId":"0c8ab18f-b97a-45bf-9eb9-e581186bf339","colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["#architecture\n","print(model)\n","\n","#No. of trianable parameters\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    \n","print(f'The model has {count_parameters(model):,} trainable parameters')\n","\n","#Initialize the pretrained embedding\n","pretrained_embeddings = TEXT.vocab.vectors\n","model.embedding.weight.data.copy_(pretrained_embeddings)\n","\n","print(pretrained_embeddings.shape)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["classifier(\n","  (embedding): Embedding(30, 100)\n","  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n","  (fc): Linear(in_features=64, out_features=4, bias=True)\n","  (act): Sigmoid()\n",")\n","The model has 62,652 trainable parameters\n","torch.Size([30, 100])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cwzh_aNHdFyA","executionInfo":{"status":"ok","timestamp":1602908186797,"user_tz":-480,"elapsed":7874,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["import torch.optim as optim\n","\n","#define optimizer and loss\n","optimizer = optim.Adam(model.parameters())\n","#optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n","#criterion = nn.BCELoss()\n","criterion = nn.CrossEntropyLoss()\n","\n","#define metric\n","def binary_accuracy(preds, y):\n","    #round predictions to the closest integer\n","    #rounded_preds = torch.round(preds)\n","    \n","    #correct = (rounded_preds == y).float()\n","    correct = (preds == y).float() \n","    acc = correct.sum() / len(correct)\n","    return acc\n","    \n","#push to cuda if available\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qln0W00adFyE","executionInfo":{"status":"ok","timestamp":1602908186798,"user_tz":-480,"elapsed":7863,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    #initialize every epoch \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    #set the model in training phase\n","    model.train()  \n","    \n","    for batch in iterator:\n","        \n","        #resets the gradients after every batch\n","        optimizer.zero_grad()   \n","        \n","        #retrieve text and no. of words\n","        text, text_lengths = batch.text   \n","        text_lengths = text_lengths.cuda()\n","            \n","        #convert to 1D tensor\n","        #predictions = model(text, text_lengths).squeeze()\n","        \n","        predictions = model(text, text_lengths).squeeze() \n","\n","        #predictions = model(text, text_lengths)\n","        #predictions = torch.max(predictions, 1)[1]\n","        #predictions = predictions.type(torch.FloatTensor)\n","        #predictions = predictions.cuda()\n","        #predictions = predictions.requires_grad_()\n","\n","        #compute the loss\n","        loss = criterion(predictions, batch.label.type(torch.LongTensor).cuda())\n","        \n","        #compute the binary accuracy\n","        acc = binary_accuracy(torch.max(predictions, 1)[1].type(torch.FloatTensor), batch.label.cpu())   \n","        \n","        #backpropage the loss and compute the gradients\n","        loss.backward()       \n","        \n","        #update the weights\n","        optimizer.step()      \n","        \n","        #loss and accuracy\n","        epoch_loss += loss.item()  \n","        epoch_acc += acc.item()    \n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"0WKYAb09dFyI","executionInfo":{"status":"ok","timestamp":1602908186799,"user_tz":-480,"elapsed":7853,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    #initialize every epoch\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    #deactivating dropout layers\n","    model.eval()\n","    \n","    #deactivates autograd\n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","        \n","            #retrieve text and no. of words\n","            text, text_lengths = batch.text\n","            text = text.cuda()\n","            text_lengths = text_lengths.cuda()\n","\n","            #convert to 1d tensor\n","            #predictions = model(text, text_lengths).squeeze()\n","\n","            predictions = model(text, text_lengths).squeeze()  \n","\n","            #predictions = model(text, text_lengths)\n","            #predictions = torch.max(predictions, 1)[1]\n","            #predictions = predictions.type(torch.FloatTensor) \n","            #predictions = predictions.cuda()\n","            #predictions = predictions.requires_grad_()\n","\n","            #compute loss and accuracy\n","            loss = criterion(predictions, batch.label.type(torch.LongTensor).cuda())\n","            print(torch.max(predictions, 1)[1].type(torch.FloatTensor), batch.label.cpu())\n","            acc = binary_accuracy(torch.max(predictions, 1)[1].type(torch.FloatTensor), batch.label.cpu())\n","\n","            #keep track of loss and accuracy\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLzNDpKLdFyK","executionInfo":{"status":"ok","timestamp":1602908187327,"user_tz":-480,"elapsed":8372,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}},"outputId":"9cf51db6-465d-4eae-a04a-20ec26f32eef","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["N_EPOCHS = 10\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","     \n","    #train the model\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    \n","    #evaluate the model\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["tensor([3., 3., 3., 3., 3., 3., 3., 3.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([3., 3., 3., 3., 3., 3., 3., 3.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([3., 1., 3., 2., 3., 2., 2., 3.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 3., 2., 2., 3., 3., 3., 3.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([3., 3., 3., 3., 3., 3., 3., 3.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","0\tTrain Loss: 1.389 | Train Acc: 17.86%\n","\t Val. Loss: 1.385 |  Val. Acc: 25.00%\n","tensor([1., 1., 1., 1., 1., 1., 1., 1.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([3., 1., 1., 1., 1., 1., 1., 1.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 1., 1., 2., 1., 2., 2., 1.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 1., 2., 2., 1., 2., 2., 2.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([1., 1., 1., 1., 3., 1., 3., 2.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","1\tTrain Loss: 1.379 | Train Acc: 35.71%\n","\t Val. Loss: 1.378 |  Val. Acc: 40.00%\n","tensor([1., 1., 1., 1., 1., 1., 1., 1.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([3., 1., 1., 1., 1., 1., 1., 1.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 1., 2., 2., 1., 2., 2., 1.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 1., 2., 2., 2., 2., 2., 2.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([1., 1., 1., 1., 1., 1., 2., 2.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","2\tTrain Loss: 1.371 | Train Acc: 43.93%\n","\t Val. Loss: 1.370 |  Val. Acc: 40.00%\n","tensor([1., 1., 1., 1., 1., 1., 1., 1.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 1., 1., 1., 1., 1., 1., 1.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 2., 2., 2., 1., 2., 2., 2.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 1., 2., 2., 2., 2., 2., 2.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([1., 1., 1., 1., 1., 2., 2., 2.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","3\tTrain Loss: 1.360 | Train Acc: 38.93%\n","\t Val. Loss: 1.359 |  Val. Acc: 30.00%\n","tensor([1., 1., 1., 1., 1., 1., 1., 1.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 1., 1., 1., 1., 1., 1., 1.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 2., 2., 2., 2., 2., 2., 2.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 2., 2., 2., 2., 2., 2., 2.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([2., 2., 2., 2., 1., 2., 2., 2.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","4\tTrain Loss: 1.348 | Train Acc: 30.36%\n","\t Val. Loss: 1.346 |  Val. Acc: 17.50%\n","tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 2., 2., 2., 2., 2., 2., 2.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 2., 2., 2., 2., 2., 2., 2.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([2., 1., 2., 1., 1., 2., 2., 2.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","5\tTrain Loss: 1.331 | Train Acc: 42.86%\n","\t Val. Loss: 1.327 |  Val. Acc: 60.00%\n","tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 2., 2., 2., 2., 2., 2., 2.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 1., 2., 2., 2., 2., 2., 2.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([1., 1., 2., 1., 1., 2., 2., 2.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","6\tTrain Loss: 1.311 | Train Acc: 65.71%\n","\t Val. Loss: 1.304 |  Val. Acc: 62.50%\n","tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 2., 2., 2., 2., 2., 2., 2.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 1., 2., 2., 2., 2., 2., 2.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([1., 1., 2., 1., 1., 2., 2., 2.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","7\tTrain Loss: 1.285 | Train Acc: 65.71%\n","\t Val. Loss: 1.277 |  Val. Acc: 62.50%\n","tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 2., 2., 2., 1., 2., 2., 2.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 1., 2., 2., 1., 2., 2., 2.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([1., 1., 1., 1., 1., 1., 2., 2.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","8\tTrain Loss: 1.254 | Train Acc: 73.93%\n","\t Val. Loss: 1.243 |  Val. Acc: 72.50%\n","tensor([0., 0., 0., 0., 0., 0., 0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0.]) tensor([3., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 1., 1., 2., 1., 2., 2., 1.]) tensor([1., 1., 3., 2., 1., 2., 2., 1.])\n","tensor([2., 1., 1., 2., 1., 2., 1., 1.]) tensor([2., 3., 1., 2., 1., 3., 1., 1.])\n","tensor([1., 1., 1., 1., 1., 1., 1., 1.]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n","9\tTrain Loss: 1.221 | Train Acc: 76.79%\n","\t Val. Loss: 1.203 |  Val. Acc: 90.00%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JZtuI6NhdFyN","executionInfo":{"status":"ok","timestamp":1602908188153,"user_tz":-480,"elapsed":9191,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":["#load weights\n","path='./saved_weights.pt'\n","model.load_state_dict(torch.load(path));\n","model.eval();\n","\n","#inference \n","import spacy\n","nlp = spacy.load('en')\n","\n","def predict(model, inv_label_map, sentence):\n","    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n","    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          #convert to integer sequence\n","    length = [len(indexed)]                                    #compute no. of words\n","    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n","    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n","    length_tensor = torch.LongTensor(length)                   #convert to tensor\n","    prediction = model(tensor, length_tensor)                  #prediction \n","    pred_label = torch.max(prediction, 1)[1].type(torch.FloatTensor)\n","    real_label = inv_label_map[pred_label[0].item()]\n","    return real_label"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"_aQOajQBdFyP","executionInfo":{"status":"ok","timestamp":1602910037635,"user_tz":-480,"elapsed":705,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}},"outputId":"b9b842e1-c78b-4113-9a42-5b79e8b85586","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","'''\n","0:cur\n","1:non\n","2:past\n","3:unknown\n","'''\n","real_label_to_word = {0 : \"current_smoker\", 1 : \"non_smoker\", 2 : \"past_smoker\", 3 : \"unknown\"}\n","import csv\n","\n","result_label=open(\"./result_label.txt\",'w+') \n","ans=open(\"./test_data_answer.txt\",'w+') \n","#count = 0 \n","#open csv file \n","with open('./test_form.csv', newline='') as csvfile:\n","#reading csv file\n","  rows = csv.reader(csvfile)\n","  for row in rows:\n","    #print(row[1])\n","    if row[1]!=\"plain_txt\":\n","      print(predict(model, inv_label_map, row[1])+\"  real label:\" + str(row[2])+\" text:\"+row[1], file=result_label)\n","      print(predict(model, inv_label_map, row[1]), file=ans)\n","      #count=count+1\n","\n","print(count)\n","\n","csvfile.close()\n","result_label.close()\n","ans.close()\n","  \n","# print(predict(model, inv_label_map, \"41 yo man with CRFs of DM Type II , high cholesterol , smoking history , family hx , HTN p / w episodes of atypical CP x 1 week , with rest and exertion .\"))\n","\n","# print(predict(model, inv_label_map, \"She denies smoking or alcohol .\"))\n","\n","# print(predict(model, inv_label_map, \"She is a former smoker of one pack per day of cigarettes for 63 years .\"))\n","\n","# print(predict(model, inv_label_map, \"unknown\"))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["40\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"26wv8SAHe8hx","executionInfo":{"status":"ok","timestamp":1602908188156,"user_tz":-480,"elapsed":9179,"user":{"displayName":"陳柏瑞","photoUrl":"","userId":"16781958207177305804"}}},"source":[""],"execution_count":20,"outputs":[]}]}